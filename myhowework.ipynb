{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:10:24.279516Z","iopub.execute_input":"2022-05-27T12:10:24.280122Z","iopub.status.idle":"2022-05-27T12:11:13.596942Z","shell.execute_reply.started":"2022-05-27T12:10:24.280007Z","shell.execute_reply":"2022-05-27T12:11:13.595596Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from pyspark.conf import SparkConf\nfrom pyspark.sql import SparkSession\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:11:13.599068Z","iopub.execute_input":"2022-05-27T12:11:13.599470Z","iopub.status.idle":"2022-05-27T12:11:13.648918Z","shell.execute_reply.started":"2022-05-27T12:11:13.599433Z","shell.execute_reply":"2022-05-27T12:11:13.648053Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nfrom matplotlib import rcParams\nimport matplotlib as mpl\n%matplotlib inline\nimport seaborn as sns\n\ncolorset10 = sns.cubehelix_palette(10, start=0.5, rot=-0.75, dark=0.15, light=0.85, reverse=True)\ncolorset25 = sns.cubehelix_palette(25, start=0.5, rot=-0.75, dark=0.15, light=0.85, reverse=True)\ncolormap = sns.cubehelix_palette(8, start=0.5, rot=-0.75, dark=0.15, light=0.85, reverse=True, as_cmap=True)\npalette1 = sns.color_palette(colorset10)\nprint(sns.palplot(palette1))\n\nrcVizParams = {\n    # setting label sizes\n    'legend.fontsize': 12,\n    'figure.figsize': (12,6),\n    'axes.labelsize': 15,\n    'axes.titlesize': 18,\n    'figure.titleweight': 'bold',\n    'xtick.labelsize': 12,\n    'ytick.labelsize': 12,\n    'figure.dpi': 120,\n    # setting colors\n    'text.color': 'slategrey',\n    'axes.labelcolor': 'slategrey',\n    'xtick.color': 'slategrey',\n    'ytick.color': 'slategrey',\n    #'font.family': ['Helvetica'],\n    \"lines.linewidth\": 1\n}\nmpl.rcParams.update(rcVizParams)\nmpl.rc('axes', facecolor='#f2f4f7', edgecolor='none', axisbelow=True, grid=True)\nmpl.rc('grid', color='w', linestyle='solid')\nplt.style.use(u'fast')","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:11:13.650324Z","iopub.execute_input":"2022-05-27T12:11:13.651250Z","iopub.status.idle":"2022-05-27T12:11:14.427202Z","shell.execute_reply.started":"2022-05-27T12:11:13.651205Z","shell.execute_reply":"2022-05-27T12:11:14.426087Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from pyspark.conf import SparkConf\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.getOrCreate()\nspark.sparkContext._conf.getAll()\nconf = spark.sparkContext._conf.setAll([('spark.executor.memory', '16g'), \n                     ('spark.app.name', 'Homework'), \n                     ('spark.executor.cores', '4'), \n                     ('spark.cores.max', '4'), \n                     ('spark.driver.memory','16g')])\nspark = SparkSession.builder.config(conf=conf).getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:11:14.430228Z","iopub.execute_input":"2022-05-27T12:11:14.431126Z","iopub.status.idle":"2022-05-27T12:11:20.620653Z","shell.execute_reply.started":"2022-05-27T12:11:14.431070Z","shell.execute_reply":"2022-05-27T12:11:20.619519Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import SQLContext\nfrom pyspark import SparkConf\nfrom pyspark.sql.functions import isnan, when, count, col\nfrom pyspark.sql.functions import mean, max, min\nimport pyspark.sql.functions as func\n\nspark = SparkSession.builder.getOrCreate()\nsqlContext = SQLContext(spark)\nprint(spark.sql(\"Select 'spark' as hello \").show())","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:11:20.625299Z","iopub.execute_input":"2022-05-27T12:11:20.627610Z","iopub.status.idle":"2022-05-27T12:11:25.352788Z","shell.execute_reply.started":"2022-05-27T12:11:20.627542Z","shell.execute_reply":"2022-05-27T12:11:25.351506Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import SQLContext\nfrom pyspark import SparkConf\n\nspark = SparkSession.builder.getOrCreate()\nconf = spark.sparkContext._conf.setAll([\n        ('spark.executor.memory', '24g'),                          \n        ('spark.app.name', 'Homework'),\n        ('spark.executor.cores', '4'),\n        ('spark.cores.max', '4'),\n        ('spark.driver.memory', '24g')                              \n])\nspark = SparkSession.builder.config(conf=conf).getOrCreate()\nprint(spark.sql(\"Select 'spark' as hello \").show())\nsqlContext = SQLContext(spark)\ndisplay('spark', 'spark', spark.sparkContext._conf.getAll(), 'sqlcontext', sqlContext)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:11:25.354071Z","iopub.execute_input":"2022-05-27T12:11:25.354506Z","iopub.status.idle":"2022-05-27T12:11:25.601542Z","shell.execute_reply.started":"2022-05-27T12:11:25.354463Z","shell.execute_reply":"2022-05-27T12:11:25.600713Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_oct = spark.read.csv('../input/ecommerce-behavior-data-from-multi-category-store/2019-Oct.csv', inferSchema=True, header=True, nullValue='NA')\ndf_oct.show(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:11:25.603218Z","iopub.execute_input":"2022-05-27T12:11:25.603961Z","iopub.status.idle":"2022-05-27T12:12:40.438156Z","shell.execute_reply.started":"2022-05-27T12:11:25.603914Z","shell.execute_reply":"2022-05-27T12:12:40.437155Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_nov = spark.read.csv('../input/ecommerce-behavior-data-from-multi-category-store/2019-Nov.csv', inferSchema=True, header=True, nullValue='NA')\ndf_nov.show(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:12:40.439375Z","iopub.execute_input":"2022-05-27T12:12:40.439798Z","iopub.status.idle":"2022-05-27T12:14:41.545626Z","shell.execute_reply.started":"2022-05-27T12:12:40.439756Z","shell.execute_reply":"2022-05-27T12:14:41.544272Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_dec = spark.read.csv('../input/ecommerce-events-history-in-cosmetics-shop/2019-Dec.csv', inferSchema=True, header=True, nullValue='NA')\ndf_dec.show(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:14:41.547135Z","iopub.execute_input":"2022-05-27T12:14:41.547796Z","iopub.status.idle":"2022-05-27T12:14:48.206214Z","shell.execute_reply.started":"2022-05-27T12:14:41.547686Z","shell.execute_reply":"2022-05-27T12:14:48.205090Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_jan = spark.read.csv('../input/ecommerce-events-history-in-cosmetics-shop/2020-Jan.csv', inferSchema=True, header=True, nullValue='NA')\ndf_jan.show(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:14:48.211408Z","iopub.execute_input":"2022-05-27T12:14:48.212014Z","iopub.status.idle":"2022-05-27T12:14:55.954662Z","shell.execute_reply.started":"2022-05-27T12:14:48.211960Z","shell.execute_reply":"2022-05-27T12:14:55.953393Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def recordCountDfCols(dataframe):\n    cols = []\n    for i in dataframe.columns:\n        cols.append(i)\n    cols = pd.DataFrame(cols)\n    record_count = dataframe.count()\n    print(\"Total columns are: {} \\nTotal records are: {} \\nThe column names are: \\n{}\".format(len(cols), record_count, cols))\n    return (record_count)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:14:55.956686Z","iopub.execute_input":"2022-05-27T12:14:55.957189Z","iopub.status.idle":"2022-05-27T12:14:55.967523Z","shell.execute_reply.started":"2022-05-27T12:14:55.957138Z","shell.execute_reply":"2022-05-27T12:14:55.965884Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"oct_record_count = recordCountDfCols(df_oct)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:14:55.970367Z","iopub.execute_input":"2022-05-27T12:14:55.971679Z","iopub.status.idle":"2022-05-27T12:15:24.099680Z","shell.execute_reply.started":"2022-05-27T12:14:55.971617Z","shell.execute_reply":"2022-05-27T12:15:24.098861Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"nov_record_count = recordCountDfCols(df_nov)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:15:24.101271Z","iopub.execute_input":"2022-05-27T12:15:24.102058Z","iopub.status.idle":"2022-05-27T12:16:07.362111Z","shell.execute_reply.started":"2022-05-27T12:15:24.102015Z","shell.execute_reply":"2022-05-27T12:16:07.361284Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dec_record_count = recordCountDfCols(df_dec)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:16:07.363445Z","iopub.execute_input":"2022-05-27T12:16:07.364340Z","iopub.status.idle":"2022-05-27T12:16:09.578629Z","shell.execute_reply.started":"2022-05-27T12:16:07.364299Z","shell.execute_reply":"2022-05-27T12:16:09.577127Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"jan_record_count = recordCountDfCols(df_jan)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:16:09.580756Z","iopub.execute_input":"2022-05-27T12:16:09.581983Z","iopub.status.idle":"2022-05-27T12:16:12.168764Z","shell.execute_reply.started":"2022-05-27T12:16:09.581923Z","shell.execute_reply":"2022-05-27T12:16:12.167962Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def nullCountPercent(dataframe, record_count):\n    df_null = dataframe.select([count(when(col(c).isNull(), c)).alias(c) for c in dataframe.columns])\n    display(print('-'*5, 'NULL VALUE COUNTS', '-'*5, 'NULL VALUE PERCENTS', '-'*5), df_null.toPandas(), ((df_null.toPandas()/record_count)*100).round(2))","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:16:12.169890Z","iopub.execute_input":"2022-05-27T12:16:12.170202Z","iopub.status.idle":"2022-05-27T12:16:12.178284Z","shell.execute_reply.started":"2022-05-27T12:16:12.170175Z","shell.execute_reply":"2022-05-27T12:16:12.176969Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"nullCountPercent(df_oct, oct_record_count)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:16:12.180185Z","iopub.execute_input":"2022-05-27T12:16:12.180653Z","iopub.status.idle":"2022-05-27T12:17:25.752030Z","shell.execute_reply.started":"2022-05-27T12:16:12.180618Z","shell.execute_reply":"2022-05-27T12:17:25.751148Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"nullCountPercent(df_nov, nov_record_count)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:17:25.753937Z","iopub.execute_input":"2022-05-27T12:17:25.755172Z","iopub.status.idle":"2022-05-27T12:19:27.907868Z","shell.execute_reply.started":"2022-05-27T12:17:25.755118Z","shell.execute_reply":"2022-05-27T12:19:27.906436Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"nullCountPercent(df_dec, dec_record_count)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:27.910066Z","iopub.execute_input":"2022-05-27T12:19:27.910701Z","iopub.status.idle":"2022-05-27T12:19:34.034241Z","shell.execute_reply.started":"2022-05-27T12:19:27.910648Z","shell.execute_reply":"2022-05-27T12:19:34.032974Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"nullCountPercent(df_jan, jan_record_count)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:34.035768Z","iopub.execute_input":"2022-05-27T12:19:34.037929Z","iopub.status.idle":"2022-05-27T12:19:40.872640Z","shell.execute_reply.started":"2022-05-27T12:19:34.037873Z","shell.execute_reply":"2022-05-27T12:19:40.871468Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import pyspark.sql.functions as sparkf\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.functions import from_unixtime, date_format, to_date\nfrom pyspark.sql.functions import to_timestamp, unix_timestamp, hour, minute\nfrom pyspark.sql.functions import split\n\ndef transformDatesColValues(dataframe):\n    dataframe = dataframe.withColumn(\n        \"event_time\",\n        to_timestamp(dataframe['event_time'], 'yyyy-MM-dd HH:mm:ss'))\n\n    dataframe = dataframe.withColumn('event_totd', date_format('event_time', 'HH:mm:ss')) \\\n                    .withColumn('event_date', date_format('event_time', 'MM-dd-yyyy'))\n    dataframe = dataframe.withColumn(\"event_date\", to_date(dataframe['event_time'], 'yyyy-MM-dd'))\\\n                    .withColumn(\"event_hour\", hour(dataframe['event_time'])+1)\\\n                    .withColumn(\"event_minute\", minute(dataframe['event_time']))\n    dataframe = dataframe.withColumn( 'Time1440Mins',\n        (dataframe['event_hour'] * 60 + dataframe['event_minute']))\n    dataframe = dataframe.withColumn('dotw_num',  date_format('event_time', 'u'))\\\n                              .withColumn('dotw_day', date_format('event_time', 'E'))\\\n                              .withColumn('dotm_num', date_format('event_time', 'd'))\\\n                              .withColumn('woty_num', date_format('event_time', 'w'))\n    dataframe = dataframe.withColumn('dotw_num',  dataframe['dotw_num'].cast('integer'))\\\n                    .withColumn('dotm_num',  dataframe['dotm_num'].cast('integer'))\\\n                    .withColumn('woty_num',  dataframe['woty_num'].cast('integer'))\n    dataframe = dataframe.withColumn('primary_cat', dataframe['category_code']) \\\n                               .withColumn('primary_cat', split(dataframe['category_code'], \"\\\\.\").getItem(0))\n    dataframe = dataframe.withColumn('product_id',  dataframe['product_id'].cast('string'))\\\n                                .withColumn('category_id',  dataframe['category_id'].cast('string'))\n    dataframe = dataframe.withColumn('PurchaseYN', (dataframe['event_type']=='purchase').cast('integer'))\n    print('Completed')\n    return(dataframe)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:40.874874Z","iopub.execute_input":"2022-05-27T12:19:40.875331Z","iopub.status.idle":"2022-05-27T12:19:40.897271Z","shell.execute_reply.started":"2022-05-27T12:19:40.875288Z","shell.execute_reply":"2022-05-27T12:19:40.895983Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df_oct = transformDatesColValues(df_oct)\ndisplay(df_oct.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:40.899804Z","iopub.execute_input":"2022-05-27T12:19:40.901275Z","iopub.status.idle":"2022-05-27T12:19:41.299379Z","shell.execute_reply.started":"2022-05-27T12:19:40.901203Z","shell.execute_reply":"2022-05-27T12:19:41.298433Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df_nov = transformDatesColValues(df_nov)\ndisplay(df_nov.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:41.300588Z","iopub.execute_input":"2022-05-27T12:19:41.301028Z","iopub.status.idle":"2022-05-27T12:19:41.533615Z","shell.execute_reply.started":"2022-05-27T12:19:41.300987Z","shell.execute_reply":"2022-05-27T12:19:41.532636Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df_dec = transformDatesColValues(df_dec)\ndisplay(df_dec.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:41.537547Z","iopub.execute_input":"2022-05-27T12:19:41.538241Z","iopub.status.idle":"2022-05-27T12:19:41.802999Z","shell.execute_reply.started":"2022-05-27T12:19:41.538204Z","shell.execute_reply":"2022-05-27T12:19:41.801191Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df_jan = transformDatesColValues(df_jan)\ndisplay(df_jan.dtypes)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:41.805006Z","iopub.execute_input":"2022-05-27T12:19:41.805548Z","iopub.status.idle":"2022-05-27T12:19:42.030761Z","shell.execute_reply.started":"2022-05-27T12:19:41.805513Z","shell.execute_reply":"2022-05-27T12:19:42.029713Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df_oct.createOrReplaceTempView(\"oct_table\")\ndf_oct.filter('PurchaseYN == 1').createOrReplaceTempView('oct_purchased')","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:42.032821Z","iopub.execute_input":"2022-05-27T12:19:42.034877Z","iopub.status.idle":"2022-05-27T12:19:42.154579Z","shell.execute_reply.started":"2022-05-27T12:19:42.034803Z","shell.execute_reply":"2022-05-27T12:19:42.153302Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"df_nov.createOrReplaceTempView(\"nov_table\")\ndf_nov.filter('PurchaseYN == 1').createOrReplaceTempView('nov_purchased')","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:42.155588Z","iopub.execute_input":"2022-05-27T12:19:42.155959Z","iopub.status.idle":"2022-05-27T12:19:42.201283Z","shell.execute_reply.started":"2022-05-27T12:19:42.155929Z","shell.execute_reply":"2022-05-27T12:19:42.200190Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df_dec.createOrReplaceTempView(\"dec_table\")\ndf_dec.filter('PurchaseYN == 1').createOrReplaceTempView('dec_purchased')","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:42.208224Z","iopub.execute_input":"2022-05-27T12:19:42.209215Z","iopub.status.idle":"2022-05-27T12:19:42.250320Z","shell.execute_reply.started":"2022-05-27T12:19:42.209146Z","shell.execute_reply":"2022-05-27T12:19:42.249503Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df_jan.createOrReplaceTempView(\"jan_table\")\ndf_jan.filter('PurchaseYN == 1').createOrReplaceTempView('jan_purchased')","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:42.251688Z","iopub.execute_input":"2022-05-27T12:19:42.252127Z","iopub.status.idle":"2022-05-27T12:19:42.287867Z","shell.execute_reply.started":"2022-05-27T12:19:42.252078Z","shell.execute_reply":"2022-05-27T12:19:42.286947Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"spark.sql('''\nselect primary_cat as Category, round(avg(price),2) as AvgPrice\nfrom oct_table\ngroup by Category\norder by AvgPrice DESC\nlimit 20''').show()\n\nspark.sql('''\nselect primary_cat as Category, round(min(price),2) as MinPrice\nfrom oct_table\ngroup by Category\norder by MinPrice ASC\nlimit 20''').show()\n\nspark.sql('''\nselect primary_cat as Category, round(max(price),2) as MaxPrice\nfrom oct_table\ngroup by Category\norder by MaxPrice DESC\nlimit 20''').show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:19:42.289054Z","iopub.execute_input":"2022-05-27T12:19:42.289519Z","iopub.status.idle":"2022-05-27T12:22:24.231263Z","shell.execute_reply.started":"2022-05-27T12:19:42.289476Z","shell.execute_reply":"2022-05-27T12:22:24.230230Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"spark.sql('''\nselect primary_cat as Category, round(avg(price),2) as AvgPrice\nfrom nov_table\ngroup by Category\norder by AvgPrice DESC\nlimit 20''').show()\n\nspark.sql('''\nselect primary_cat as Category, round(min(price),2) as MinPrice\nfrom nov_table\ngroup by Category\norder by MinPrice ASC\nlimit 20''').show()\n\nspark.sql('''\nselect primary_cat as Category, round(max(price),2) as MaxPrice\nfrom nov_table\ngroup by Category\norder by MaxPrice DESC\nlimit 20''').show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:22:24.232440Z","iopub.execute_input":"2022-05-27T12:22:24.232823Z","iopub.status.idle":"2022-05-27T12:26:40.483345Z","shell.execute_reply.started":"2022-05-27T12:22:24.232792Z","shell.execute_reply":"2022-05-27T12:26:40.481023Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"spark.sql('''\nselect brand as Brand, round(avg(price),2) as AvgPrice\nfrom oct_table\ngroup by brand\norder by AvgPrice DESC\nlimit 20''').show()\n\nspark.sql('''\nselect brand as Brand, round(min(price),2) as MinPrice\nfrom oct_table\ngroup by brand\norder by MinPrice ASC\nlimit 20''').show()\n\nspark.sql('''\nselect brand as Brand, round(max(price),2) as MaxPrice\nfrom oct_table\ngroup by brand\norder by MaxPrice DESC\nlimit 20''').show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:26:40.490282Z","iopub.execute_input":"2022-05-27T12:26:40.492040Z","iopub.status.idle":"2022-05-27T12:29:02.296068Z","shell.execute_reply.started":"2022-05-27T12:26:40.491961Z","shell.execute_reply":"2022-05-27T12:29:02.294673Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"spark.sql('''\nselect brand as Brand, round(avg(price),2) as AvgPrice\nfrom nov_table\ngroup by brand\norder by AvgPrice DESC\nlimit 20''').show()\n\nspark.sql('''\nselect brand as Brand, round(min(price),2) as MinPrice\nfrom nov_table\ngroup by brand\norder by MinPrice ASC\nlimit 20''').show()\n\nspark.sql('''\nselect brand as Brand, round(max(price),2) as MaxPrice\nfrom nov_table\ngroup by brand\norder by MaxPrice DESC\nlimit 20''').show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:29:02.297575Z","iopub.execute_input":"2022-05-27T12:29:02.298937Z","iopub.status.idle":"2022-05-27T12:32:35.530847Z","shell.execute_reply.started":"2022-05-27T12:29:02.298885Z","shell.execute_reply":"2022-05-27T12:32:35.530016Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"spark.sql('''\nselect primary_cat as Category, count(primary_cat) as Popularity\nfrom oct_table\ngroup by Category\norder by Popularity DESC\nlimit 20''').show()\n\nspark.sql('''\nselect brand as Brand, count(brand) as Popularity\nfrom oct_table\ngroup by Brand\norder by Popularity DESC\nlimit 20''').show()\n\nspark.sql('''\nselect user_id as User, count(user_id) as Popularity\nfrom oct_table\ngroup by User\norder by Popularity DESC\nlimit 20''').show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:32:35.531923Z","iopub.execute_input":"2022-05-27T12:32:35.532274Z","iopub.status.idle":"2022-05-27T12:34:46.498320Z","shell.execute_reply.started":"2022-05-27T12:32:35.532244Z","shell.execute_reply":"2022-05-27T12:34:46.497182Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"spark.sql('''\nselect primary_cat as Category, count(primary_cat) as Popularity\nfrom nov_table\ngroup by Category\norder by Popularity DESC\nlimit 20''').show()\n\nspark.sql('''\nselect brand as Brand, count(brand) as Popularity\nfrom nov_table\ngroup by Brand\norder by Popularity DESC\nlimit 20''').show()\n\nspark.sql('''\nselect user_id as User, count(user_id) as Popularity\nfrom nov_table\ngroup by User\norder by Popularity DESC\nlimit 20''').show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:34:46.500201Z","iopub.execute_input":"2022-05-27T12:34:46.501414Z","iopub.status.idle":"2022-05-27T12:38:34.449121Z","shell.execute_reply.started":"2022-05-27T12:34:46.501366Z","shell.execute_reply":"2022-05-27T12:38:34.447928Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"spark.sql('''\nSELECT event_type as Event, \n    round(count(price),2) as Count,\n    round(mean(price),2) as Mean,\n    round(std(price),2) as Std,\n    round(min(price),2) as Min,\n    round(max(price),2) as Max\nFROM oct_table\ngroup by Event\n''').show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:38:34.455515Z","iopub.execute_input":"2022-05-27T12:38:34.456222Z","iopub.status.idle":"2022-05-27T12:39:30.372572Z","shell.execute_reply.started":"2022-05-27T12:38:34.456189Z","shell.execute_reply":"2022-05-27T12:39:30.371505Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"spark.sql('''\nSELECT event_type as Event, \n    round(count(price),2) as Count,\n    round(mean(price),2) as Mean,\n    round(std(price),2) as Std,\n    round(min(price),2) as Min,\n    round(max(price),2) as Max\nFROM nov_table\ngroup by Event\n''').show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:39:30.373907Z","iopub.execute_input":"2022-05-27T12:39:30.374360Z","iopub.status.idle":"2022-05-27T12:41:00.270090Z","shell.execute_reply.started":"2022-05-27T12:39:30.374318Z","shell.execute_reply":"2022-05-27T12:41:00.268969Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"df_oct.groupby('primary_cat')\\\n        .pivot('event_type')\\\n        .agg(func.round(mean('price'), 2))\\\n        .sort('primary_cat').show(20)\n\ndf_oct.groupby('brand')\\\n        .pivot('event_type')\\\n        .agg(func.round(mean('price'), 2))\\\n        .sort('brand').show(20)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:41:00.271516Z","iopub.execute_input":"2022-05-27T12:41:00.272026Z","iopub.status.idle":"2022-05-27T12:44:09.298973Z","shell.execute_reply.started":"2022-05-27T12:41:00.271980Z","shell.execute_reply":"2022-05-27T12:44:09.297795Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"df_nov.groupby('primary_cat')\\\n        .pivot('event_type')\\\n        .agg(func.round(mean('price'), 2))\\\n        .sort('primary_cat').show(20)\n\ndf_nov.groupby('brand')\\\n        .pivot('event_type')\\\n        .agg(func.round(mean('price'), 2))\\\n        .sort('brand').show(20)","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:44:09.300323Z","iopub.execute_input":"2022-05-27T12:44:09.300770Z","iopub.status.idle":"2022-05-27T12:49:15.151982Z","shell.execute_reply.started":"2022-05-27T12:44:09.300726Z","shell.execute_reply":"2022-05-27T12:49:15.150728Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Revenue per product id ~10mins\ntopRevProducts = spark.sql('''\nSELECT round(sum(price),2) as Revenue, product_id as ProductID \nFROM oct_purchased \nGROUP BY ProductID \nORDER BY Revenue DESC \nLimit 25\n''').toPandas()\ntopRevProductsPandas = topRevProducts.reset_index()\n\n# Revenue per user_id\ntopRevUser = spark.sql('''\nSELECT round(sum(price),2) as Revenue, user_id as UserID \nFROM oct_purchased \nGROUP BY UserID \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevUserPandas = topRevUser.reset_index()\n\n# Revenue per brand\ntopRevBrandPandas = spark.sql('''\nSELECT round(sum(price),2) as Revenue, brand as Brand \nFROM oct_purchased \nWHERE Brand IS NOT NULL \nGROUP BY Brand \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevBrandPandas = topRevBrandPandas.reset_index()\n\n# Revenue per Category\ntopRevCatPandas = spark.sql('''\nSELECT round(sum(price),2) as Revenue, primary_cat as Category \nFROM oct_purchased \nWHERE primary_cat IS NOT NULL \nGROUP BY Category \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevCatPandas = topRevCatPandas.reset_index()\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=False, sharey=False, figsize=(12,12))\norder1 = list(topRevProductsPandas['ProductID'])\ng1 = sns.barplot(y='ProductID', x='Revenue', orient='h', data=topRevProductsPandas, palette=colorset25, hue='index', dodge=False, alpha=0.9, ax=ax1, order=order1)\n\norder2 = list(topRevUserPandas['UserID'])\ng2 = sns.barplot(y='UserID', x='Revenue', orient='h', data=topRevUserPandas, palette=colorset25, hue='index', dodge=False, alpha=0.9, ax=ax2, order=order2)\n\norder3 = list(topRevBrandPandas['Brand'])\ng3 = sns.barplot(y='Brand', x='Revenue', data=topRevBrandPandas, palette=colorset25, estimator=np.sum, hue='index', dodge=False, alpha=0.9, ax=ax3, order=order3)\n\norder4 = list(topRevCatPandas['Category'])\ng4 = sns.barplot(y='Category', x='Revenue', data=topRevCatPandas, palette=colorset10, estimator=np.sum, hue='index', dodge=False, alpha=0.9, ax=ax4, order=order4)\n\ng1.set_title('Revenue Per Product ID - Top 25')\ng2.set_title('Revenue Per User - Top 25')\ng3.set_title('Revenue Per Brand - Top 25')\ng4.set_title('Revenue Per Category - Top 25')\n\nplt.setp(g1.get_xticklabels(), rotation=30)\nplt.setp(g2.get_xticklabels(), rotation=30)\nplt.setp(g3.get_xticklabels(), rotation=30)\nplt.setp(g4.get_xticklabels(), rotation=30)\n\ng1.legend_.remove()\ng2.legend_.remove()\ng3.legend_.remove()\ng4.legend_.remove()\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:49:15.154759Z","iopub.execute_input":"2022-05-27T12:49:15.156260Z","iopub.status.idle":"2022-05-27T12:52:32.172739Z","shell.execute_reply.started":"2022-05-27T12:49:15.156175Z","shell.execute_reply":"2022-05-27T12:52:32.171658Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Revenue per product id ~10mins\ntopRevProducts = spark.sql('''\nSELECT round(sum(price),2) as Revenue, product_id as ProductID \nFROM nov_purchased \nGROUP BY ProductID \nORDER BY Revenue DESC \nLimit 25\n''').toPandas()\ntopRevProductsPandas = topRevProducts.reset_index()\n\n# Revenue per user_id\ntopRevUser = spark.sql('''\nSELECT round(sum(price),2) as Revenue, user_id as UserID \nFROM nov_purchased \nGROUP BY UserID \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevUserPandas = topRevUser.reset_index()\n\n# Revenue per brand\ntopRevBrandPandas = spark.sql('''\nSELECT round(sum(price),2) as Revenue, brand as Brand \nFROM nov_purchased \nWHERE Brand IS NOT NULL \nGROUP BY Brand \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevBrandPandas = topRevBrandPandas.reset_index()\n\n# Revenue per Category\ntopRevCatPandas = spark.sql('''\nSELECT round(sum(price),2) as Revenue, primary_cat as Category \nFROM nov_purchased \nWHERE primary_cat IS NOT NULL \nGROUP BY Category \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevCatPandas = topRevCatPandas.reset_index()\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=False, sharey=False, figsize=(12,12))\norder1 = list(topRevProductsPandas['ProductID'])\ng1 = sns.barplot(y='ProductID', x='Revenue', orient='h', data=topRevProductsPandas, palette=colorset25, hue='index', dodge=False, alpha=0.9, ax=ax1, order=order1)\n\norder2 = list(topRevUserPandas['UserID'])\ng2 = sns.barplot(y='UserID', x='Revenue', orient='h', data=topRevUserPandas, palette=colorset25, hue='index', dodge=False, alpha=0.9, ax=ax2, order=order2)\n\norder3 = list(topRevBrandPandas['Brand'])\ng3 = sns.barplot(y='Brand', x='Revenue', data=topRevBrandPandas, palette=colorset25, estimator=np.sum, hue='index', dodge=False, alpha=0.9, ax=ax3, order=order3)\n\norder4 = list(topRevCatPandas['Category'])\ng4 = sns.barplot(y='Category', x='Revenue', data=topRevCatPandas, palette=colorset10, estimator=np.sum, hue='index', dodge=False, alpha=0.9, ax=ax4, order=order4)\n\ng1.set_title('Revenue Per Product ID - Top 25')\ng2.set_title('Revenue Per User - Top 25')\ng3.set_title('Revenue Per Brand - Top 25')\ng4.set_title('Revenue Per Category - Top 25')\n\nplt.setp(g1.get_xticklabels(), rotation=30)\nplt.setp(g2.get_xticklabels(), rotation=30)\nplt.setp(g3.get_xticklabels(), rotation=30)\nplt.setp(g4.get_xticklabels(), rotation=30)\n\ng1.legend_.remove()\ng2.legend_.remove()\ng3.legend_.remove()\ng4.legend_.remove()\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:52:32.174503Z","iopub.execute_input":"2022-05-27T12:52:32.175101Z","iopub.status.idle":"2022-05-27T12:57:53.437569Z","shell.execute_reply.started":"2022-05-27T12:52:32.175060Z","shell.execute_reply":"2022-05-27T12:57:53.436647Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Revenue per product id ~10mins\ntopRevProducts = spark.sql('''\nSELECT round(sum(price),2) as Revenue, product_id as ProductID \nFROM dec_purchased \nGROUP BY ProductID \nORDER BY Revenue DESC \nLimit 25\n''').toPandas()\ntopRevProductsPandas = topRevProducts.reset_index()\n\n# Revenue per user_id\ntopRevUser = spark.sql('''\nSELECT round(sum(price),2) as Revenue, user_id as UserID \nFROM dec_purchased \nGROUP BY UserID \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevUserPandas = topRevUser.reset_index()\n\n# Revenue per brand\ntopRevBrandPandas = spark.sql('''\nSELECT round(sum(price),2) as Revenue, brand as Brand \nFROM dec_purchased \nWHERE Brand IS NOT NULL \nGROUP BY Brand \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevBrandPandas = topRevBrandPandas.reset_index()\n\n# Revenue per Category\ntopRevCatPandas = spark.sql('''\nSELECT round(sum(price),2) as Revenue, primary_cat as Category \nFROM dec_purchased \nWHERE primary_cat IS NOT NULL \nGROUP BY Category \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevCatPandas = topRevCatPandas.reset_index()\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=False, sharey=False, figsize=(12,12))\norder1 = list(topRevProductsPandas['ProductID'])\ng1 = sns.barplot(y='ProductID', x='Revenue', orient='h', data=topRevProductsPandas, palette=colorset25, hue='index', dodge=False, alpha=0.9, ax=ax1, order=order1)\n\norder2 = list(topRevUserPandas['UserID'])\ng2 = sns.barplot(y='UserID', x='Revenue', orient='h', data=topRevUserPandas, palette=colorset25, hue='index', dodge=False, alpha=0.9, ax=ax2, order=order2)\n\norder3 = list(topRevBrandPandas['Brand'])\ng3 = sns.barplot(y='Brand', x='Revenue', data=topRevBrandPandas, palette=colorset25, estimator=np.sum, hue='index', dodge=False, alpha=0.9, ax=ax3, order=order3)\n\norder4 = list(topRevCatPandas['Category'])\ng4 = sns.barplot(y='Category', x='Revenue', data=topRevCatPandas, palette=colorset10, estimator=np.sum, hue='index', dodge=False, alpha=0.9, ax=ax4, order=order4)\n\ng1.set_title('Revenue Per Product ID - Top 25')\ng2.set_title('Revenue Per User - Top 25')\ng3.set_title('Revenue Per Brand - Top 25')\ng4.set_title('Revenue Per Category - Top 25')\n\nplt.setp(g1.get_xticklabels(), rotation=30)\nplt.setp(g2.get_xticklabels(), rotation=30)\nplt.setp(g3.get_xticklabels(), rotation=30)\nplt.setp(g4.get_xticklabels(), rotation=30)\n\ng1.legend_.remove()\ng2.legend_.remove()\ng3.legend_.remove()\ng4.legend_.remove()\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:57:53.440019Z","iopub.execute_input":"2022-05-27T12:57:53.440904Z","iopub.status.idle":"2022-05-27T12:58:16.088120Z","shell.execute_reply.started":"2022-05-27T12:57:53.440863Z","shell.execute_reply":"2022-05-27T12:58:16.087034Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Revenue per product id ~10mins\ntopRevProducts = spark.sql('''\nSELECT round(sum(price),2) as Revenue, product_id as ProductID \nFROM jan_purchased \nGROUP BY ProductID \nORDER BY Revenue DESC \nLimit 25\n''').toPandas()\ntopRevProductsPandas = topRevProducts.reset_index()\n\n# Revenue per user_id\ntopRevUser = spark.sql('''\nSELECT round(sum(price),2) as Revenue, user_id as UserID \nFROM jan_purchased \nGROUP BY UserID \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevUserPandas = topRevUser.reset_index()\n\n# Revenue per brand\ntopRevBrandPandas = spark.sql('''\nSELECT round(sum(price),2) as Revenue, brand as Brand \nFROM jan_purchased \nWHERE Brand IS NOT NULL \nGROUP BY Brand \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevBrandPandas = topRevBrandPandas.reset_index()\n\n# Revenue per Category\ntopRevCatPandas = spark.sql('''\nSELECT round(sum(price),2) as Revenue, primary_cat as Category \nFROM jan_purchased \nWHERE primary_cat IS NOT NULL \nGROUP BY Category \nORDER BY Revenue DESC \nLimit 25''').toPandas()\ntopRevCatPandas = topRevCatPandas.reset_index()\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=False, sharey=False, figsize=(12,12))\norder1 = list(topRevProductsPandas['ProductID'])\ng1 = sns.barplot(y='ProductID', x='Revenue', orient='h', data=topRevProductsPandas, palette=colorset25, hue='index', dodge=False, alpha=0.9, ax=ax1, order=order1)\n\norder2 = list(topRevUserPandas['UserID'])\ng2 = sns.barplot(y='UserID', x='Revenue', orient='h', data=topRevUserPandas, palette=colorset25, hue='index', dodge=False, alpha=0.9, ax=ax2, order=order2)\n\norder3 = list(topRevBrandPandas['Brand'])\ng3 = sns.barplot(y='Brand', x='Revenue', data=topRevBrandPandas, palette=colorset25, estimator=np.sum, hue='index', dodge=False, alpha=0.9, ax=ax3, order=order3)\n\norder4 = list(topRevCatPandas['Category'])\ng4 = sns.barplot(y='Category', x='Revenue', data=topRevCatPandas, palette=colorset10, estimator=np.sum, hue='index', dodge=False, alpha=0.9, ax=ax4, order=order4)\n\ng1.set_title('Revenue Per Product ID - Top 25')\ng2.set_title('Revenue Per User - Top 25')\ng3.set_title('Revenue Per Brand - Top 25')\ng4.set_title('Revenue Per Category - Top 25')\n\nplt.setp(g1.get_xticklabels(), rotation=30)\nplt.setp(g2.get_xticklabels(), rotation=30)\nplt.setp(g3.get_xticklabels(), rotation=30)\nplt.setp(g4.get_xticklabels(), rotation=30)\n\ng1.legend_.remove()\ng2.legend_.remove()\ng3.legend_.remove()\ng4.legend_.remove()\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:58:16.089788Z","iopub.execute_input":"2022-05-27T12:58:16.090398Z","iopub.status.idle":"2022-05-27T12:58:42.404787Z","shell.execute_reply.started":"2022-05-27T12:58:16.090355Z","shell.execute_reply":"2022-05-27T12:58:42.403820Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\nhourPurchasePerDotm = spark.sql('''\nSELECT \n    round(avg(hourpurchased), 2) as AvgPurchasePerHour, \n    sum(hourpurchased) as SumPurchasePerHour, \n    event_hour as EventHour \nFROM \n    (select sum(PurchaseYN) as hourpurchased, dotm_num, event_hour \n    from oct_purchased\n    group by dotm_num, event_hour)\nGROUP BY event_hour\n''')\n\nhourPurchasePerDotm_sum = hourPurchasePerDotm.select(\n    'EventHour', 'SumPurchasePerHour').toPandas()\nhourPurchasePerDotm_avg = hourPurchasePerDotm.select(\n    'EventHour', 'AvgPurchasePerHour').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='EventHour', y='SumPurchasePerHour', data=hourPurchasePerDotm_sum, ax=ax1, markers='o', linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    hourPurchasePerDotm_sum.groupby('EventHour')\n    ['SumPurchasePerHour'].sum()).sort_values('SumPurchasePerHour',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 60},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    hourPurchasePerDotm_avg.groupby('EventHour')\n    ['AvgPurchasePerHour'].sum()).sort_values('AvgPurchasePerHour',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 60},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='EventHour', y='AvgPurchasePerHour', data=hourPurchasePerDotm_avg, ax=ax4, markers='o', linestyles='dashdot')\n\nmeanSum = round(hourPurchasePerDotm_sum['SumPurchasePerHour'].mean(),1)\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(meanSum),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = round(hourPurchasePerDotm_avg['AvgPurchasePerHour'].mean(),1)\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(meanAvg),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Hour for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Hour for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Hour of the Day\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Hour of the Day\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T12:58:42.406539Z","iopub.execute_input":"2022-05-27T12:58:42.406928Z","iopub.status.idle":"2022-05-27T13:00:09.155038Z","shell.execute_reply.started":"2022-05-27T12:58:42.406898Z","shell.execute_reply":"2022-05-27T13:00:09.150971Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\nhourPurchasePerDotm = spark.sql('''\nSELECT \n    round(avg(hourpurchased), 2) as AvgPurchasePerHour, \n    sum(hourpurchased) as SumPurchasePerHour, \n    event_hour as EventHour \nFROM \n    (select sum(PurchaseYN) as hourpurchased, dotm_num, event_hour \n    from nov_purchased\n    group by dotm_num, event_hour)\nGROUP BY event_hour\n''')\n\nhourPurchasePerDotm_sum = hourPurchasePerDotm.select(\n    'EventHour', 'SumPurchasePerHour').toPandas()\nhourPurchasePerDotm_avg = hourPurchasePerDotm.select(\n    'EventHour', 'AvgPurchasePerHour').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='EventHour', y='SumPurchasePerHour', data=hourPurchasePerDotm_sum, ax=ax1, markers='o', linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    hourPurchasePerDotm_sum.groupby('EventHour')\n    ['SumPurchasePerHour'].sum()).sort_values('SumPurchasePerHour',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 60},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    hourPurchasePerDotm_avg.groupby('EventHour')\n    ['AvgPurchasePerHour'].sum()).sort_values('AvgPurchasePerHour',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 60},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='EventHour', y='AvgPurchasePerHour', data=hourPurchasePerDotm_avg, ax=ax4, markers='o', linestyles='dashdot')\n\nmeanSum = round(hourPurchasePerDotm_sum['SumPurchasePerHour'].mean(),1)\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(meanSum),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = round(hourPurchasePerDotm_avg['AvgPurchasePerHour'].mean(),1)\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(meanAvg),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Hour for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Hour for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Hour of the Day\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Hour of the Day\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:02:35.561628Z","iopub.execute_input":"2022-05-27T13:02:35.562129Z","iopub.status.idle":"2022-05-27T13:04:50.992007Z","shell.execute_reply.started":"2022-05-27T13:02:35.562093Z","shell.execute_reply":"2022-05-27T13:04:50.978193Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\nhourPurchasePerDotm = spark.sql('''\nSELECT \n    round(avg(hourpurchased), 2) as AvgPurchasePerHour, \n    sum(hourpurchased) as SumPurchasePerHour, \n    event_hour as EventHour \nFROM \n    (select sum(PurchaseYN) as hourpurchased, dotm_num, event_hour \n    from dec_purchased\n    group by dotm_num, event_hour)\nGROUP BY event_hour\n''')\n\nhourPurchasePerDotm_sum = hourPurchasePerDotm.select(\n    'EventHour', 'SumPurchasePerHour').toPandas()\nhourPurchasePerDotm_avg = hourPurchasePerDotm.select(\n    'EventHour', 'AvgPurchasePerHour').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='EventHour', y='SumPurchasePerHour', data=hourPurchasePerDotm_sum, ax=ax1, markers='o', linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    hourPurchasePerDotm_sum.groupby('EventHour')\n    ['SumPurchasePerHour'].sum()).sort_values('SumPurchasePerHour',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 60},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    hourPurchasePerDotm_avg.groupby('EventHour')\n    ['AvgPurchasePerHour'].sum()).sort_values('AvgPurchasePerHour',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 60},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='EventHour', y='AvgPurchasePerHour', data=hourPurchasePerDotm_avg, ax=ax4, markers='o', linestyles='dashdot')\n\nmeanSum = round(hourPurchasePerDotm_sum['SumPurchasePerHour'].mean(),1)\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(meanSum),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = round(hourPurchasePerDotm_avg['AvgPurchasePerHour'].mean(),1)\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(meanAvg),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Hour for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Hour for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Hour of the Day\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Hour of the Day\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:07:38.312779Z","iopub.execute_input":"2022-05-27T13:07:38.313299Z","iopub.status.idle":"2022-05-27T13:07:47.147097Z","shell.execute_reply.started":"2022-05-27T13:07:38.313266Z","shell.execute_reply":"2022-05-27T13:07:47.146126Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\nhourPurchasePerDotm = spark.sql('''\nSELECT \n    round(avg(hourpurchased), 2) as AvgPurchasePerHour, \n    sum(hourpurchased) as SumPurchasePerHour, \n    event_hour as EventHour \nFROM \n    (select sum(PurchaseYN) as hourpurchased, dotm_num, event_hour \n    from jan_purchased\n    group by dotm_num, event_hour)\nGROUP BY event_hour\n''')\n\nhourPurchasePerDotm_sum = hourPurchasePerDotm.select(\n    'EventHour', 'SumPurchasePerHour').toPandas()\nhourPurchasePerDotm_avg = hourPurchasePerDotm.select(\n    'EventHour', 'AvgPurchasePerHour').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='EventHour', y='SumPurchasePerHour', data=hourPurchasePerDotm_sum, ax=ax1, markers='o', linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    hourPurchasePerDotm_sum.groupby('EventHour')\n    ['SumPurchasePerHour'].sum()).sort_values('SumPurchasePerHour',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 60},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    hourPurchasePerDotm_avg.groupby('EventHour')\n    ['AvgPurchasePerHour'].sum()).sort_values('AvgPurchasePerHour',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 60},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='EventHour', y='AvgPurchasePerHour', data=hourPurchasePerDotm_avg, ax=ax4, markers='o', linestyles='dashdot')\n\nmeanSum = round(hourPurchasePerDotm_sum['SumPurchasePerHour'].mean(),1)\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(meanSum),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = round(hourPurchasePerDotm_avg['AvgPurchasePerHour'].mean(),1)\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(meanAvg),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Hour for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Hour for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Hour of the Day\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Hour of the Day\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:08:38.619080Z","iopub.execute_input":"2022-05-27T13:08:38.619569Z","iopub.status.idle":"2022-05-27T13:08:48.765294Z","shell.execute_reply.started":"2022-05-27T13:08:38.619520Z","shell.execute_reply":"2022-05-27T13:08:48.763647Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\ndayPurchasePerDotm = spark.sql('''\nSELECT \n    round(avg(dayPurchased), 2) as AvgPurchasePerDay,\n    sum(dayPurchased) as SumPurchasePerDay,\n    dotm_num as DayoftheMonth\nFROM \n    (select sum(PurchaseYN) as dayPurchased, dotm_num, event_hour\n    from oct_purchased\n    group by event_hour, dotm_num)\nGROUP BY dotm_num\n''')\n\n\ndayPurchasePerDotm_sum = dayPurchasePerDotm.select('DayoftheMonth', 'SumPurchasePerDay').toPandas()\ndayPurchasePerDotm_avg = dayPurchasePerDotm.select('DayoftheMonth', 'AvgPurchasePerDay').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='DayoftheMonth', y='SumPurchasePerDay', data=dayPurchasePerDotm_sum, ax=ax1, markers='o', linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    dayPurchasePerDotm_sum.groupby('DayoftheMonth')\n    ['SumPurchasePerDay'].sum()).sort_values('SumPurchasePerDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 65},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    dayPurchasePerDotm_avg.groupby('DayoftheMonth')\n    ['AvgPurchasePerDay'].sum()).sort_values('AvgPurchasePerDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 65},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='DayoftheMonth', y='AvgPurchasePerDay', data=dayPurchasePerDotm_avg, ax=ax4, markers='o', linestyles='dashdot')\n\nmeanSum = round(dayPurchasePerDotm_sum['SumPurchasePerDay'].mean(),1)\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(meanSum),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = round(dayPurchasePerDotm_avg['AvgPurchasePerDay'].mean(), 1)\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(meanAvg),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Day for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Day for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Day of the Month\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Day of the Month\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:16:09.949602Z","iopub.execute_input":"2022-05-27T13:16:09.950050Z","iopub.status.idle":"2022-05-27T13:17:34.655446Z","shell.execute_reply.started":"2022-05-27T13:16:09.950017Z","shell.execute_reply":"2022-05-27T13:17:34.654392Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\ndayPurchasePerDotm = spark.sql('''\nSELECT \n    round(avg(dayPurchased), 2) as AvgPurchasePerDay,\n    sum(dayPurchased) as SumPurchasePerDay,\n    dotm_num as DayoftheMonth\nFROM \n    (select sum(PurchaseYN) as dayPurchased, dotm_num, event_hour\n    from nov_purchased\n    group by event_hour, dotm_num)\nGROUP BY dotm_num\n''')\n\n\ndayPurchasePerDotm_sum = dayPurchasePerDotm.select('DayoftheMonth', 'SumPurchasePerDay').toPandas()\ndayPurchasePerDotm_avg = dayPurchasePerDotm.select('DayoftheMonth', 'AvgPurchasePerDay').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='DayoftheMonth', y='SumPurchasePerDay', data=dayPurchasePerDotm_sum, ax=ax1, markers='o', linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    dayPurchasePerDotm_sum.groupby('DayoftheMonth')\n    ['SumPurchasePerDay'].sum()).sort_values('SumPurchasePerDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 65},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    dayPurchasePerDotm_avg.groupby('DayoftheMonth')\n    ['AvgPurchasePerDay'].sum()).sort_values('AvgPurchasePerDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 65},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='DayoftheMonth', y='AvgPurchasePerDay', data=dayPurchasePerDotm_avg, ax=ax4, markers='o', linestyles='dashdot')\n\nmeanSum = round(dayPurchasePerDotm_sum['SumPurchasePerDay'].mean(), 1)\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(meanSum),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = round(dayPurchasePerDotm_avg['AvgPurchasePerDay'].mean(), 1)\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(meanAvg),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Day for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Day for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Day of the Month\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Day of the Month\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:17:49.744023Z","iopub.execute_input":"2022-05-27T13:17:49.744497Z","iopub.status.idle":"2022-05-27T13:20:03.036127Z","shell.execute_reply.started":"2022-05-27T13:17:49.744429Z","shell.execute_reply":"2022-05-27T13:20:03.034624Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\ndayPurchasePerDotm = spark.sql('''\nSELECT \n    round(avg(dayPurchased), 2) as AvgPurchasePerDay,\n    sum(dayPurchased) as SumPurchasePerDay,\n    dotm_num as DayoftheMonth\nFROM \n    (select sum(PurchaseYN) as dayPurchased, dotm_num, event_hour\n    from dec_purchased\n    group by event_hour, dotm_num)\nGROUP BY dotm_num\n''')\n\n\ndayPurchasePerDotm_sum = dayPurchasePerDotm.select('DayoftheMonth', 'SumPurchasePerDay').toPandas()\ndayPurchasePerDotm_avg = dayPurchasePerDotm.select('DayoftheMonth', 'AvgPurchasePerDay').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='DayoftheMonth', y='SumPurchasePerDay', data=dayPurchasePerDotm_sum, ax=ax1, markers='o', linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    dayPurchasePerDotm_sum.groupby('DayoftheMonth')\n    ['SumPurchasePerDay'].sum()).sort_values('SumPurchasePerDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 65},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    dayPurchasePerDotm_avg.groupby('DayoftheMonth')\n    ['AvgPurchasePerDay'].sum()).sort_values('AvgPurchasePerDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 65},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='DayoftheMonth', y='AvgPurchasePerDay', data=dayPurchasePerDotm_avg, ax=ax4, markers='o', linestyles='dashdot')\n\nmeanSum = round(dayPurchasePerDotm_sum['SumPurchasePerDay'].mean(), 1)\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(meanSum),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = round(dayPurchasePerDotm_avg['AvgPurchasePerDay'].mean(), 1)\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(meanAvg),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Day for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Day for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Day of the Month\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Day of the Month\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:22:11.944387Z","iopub.execute_input":"2022-05-27T13:22:11.945446Z","iopub.status.idle":"2022-05-27T13:22:21.128180Z","shell.execute_reply.started":"2022-05-27T13:22:11.945407Z","shell.execute_reply":"2022-05-27T13:22:21.126806Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\ndayPurchasePerDotm = spark.sql('''\nSELECT \n    round(avg(dayPurchased), 2) as AvgPurchasePerDay,\n    sum(dayPurchased) as SumPurchasePerDay,\n    dotm_num as DayoftheMonth\nFROM \n    (select sum(PurchaseYN) as dayPurchased, dotm_num, event_hour\n    from jan_purchased\n    group by event_hour, dotm_num)\nGROUP BY dotm_num\n''')\n\ndayPurchasePerDotm_sum = dayPurchasePerDotm.select('DayoftheMonth', 'SumPurchasePerDay').toPandas()\ndayPurchasePerDotm_avg = dayPurchasePerDotm.select('DayoftheMonth', 'AvgPurchasePerDay').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='DayoftheMonth', y='SumPurchasePerDay', data=dayPurchasePerDotm_sum, ax=ax1, markers='o', linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    dayPurchasePerDotm_sum.groupby('DayoftheMonth')\n    ['SumPurchasePerDay'].sum()).sort_values('SumPurchasePerDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 65},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    dayPurchasePerDotm_avg.groupby('DayoftheMonth')\n    ['AvgPurchasePerDay'].sum()).sort_values('AvgPurchasePerDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 65},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='DayoftheMonth', y='AvgPurchasePerDay', data=dayPurchasePerDotm_avg, ax=ax4, markers='o', linestyles='dashdot')\n\nmeanSum = round(dayPurchasePerDotm_sum['SumPurchasePerDay'].mean(), 1)\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(meanSum),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = round(dayPurchasePerDotm_avg['AvgPurchasePerWkDay'].mean(), 1)\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(meanAvg),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='left',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Day for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Day for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Day of the Month\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Day of the Month\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:22:44.817664Z","iopub.execute_input":"2022-05-27T13:22:44.818138Z","iopub.status.idle":"2022-05-27T13:22:55.283772Z","shell.execute_reply.started":"2022-05-27T13:22:44.818105Z","shell.execute_reply":"2022-05-27T13:22:55.282476Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\nwkDayPurchasePerWotM = spark.sql('''\nSELECT \n    round(avg(WkDayPurchased), 2) as AvgPurchasePerWkDay, \n    sum(WkDayPurchased) as SumPurchasePerWkDay, \n    dotw_day as WkDayoftheMonth\nFROM \n    (select sum(PurchaseYN) as WkDayPurchased, dotw_day, woty_num\n    from oct_purchased\n    group by dotw_day, woty_num)\nGROUP BY dotw_day\n''')\n\nwkDayPurchasePerWotM_sum = wkDayPurchasePerWotM.select('WkDayoftheMonth', 'SumPurchasePerWkDay').toPandas()\nwkDayPurchasePerWotM_avg = wkDayPurchasePerWotM.select('WkDayoftheMonth', 'AvgPurchasePerWkDay').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='WkDayoftheMonth',\n                   y='SumPurchasePerWkDay',\n                   data=wkDayPurchasePerWotM_sum,\n                   order=['Mon','Tue', 'Wed', 'Thu','Fri', 'Sat', 'Sun'],\n                   ax=ax1,\n                   markers='o',\n                   linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    wkDayPurchasePerWotM_sum.groupby('WkDayoftheMonth')\n    ['SumPurchasePerWkDay'].sum()).sort_values('SumPurchasePerWkDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 70},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    wkDayPurchasePerWotM_avg.groupby('WkDayoftheMonth')\n    ['AvgPurchasePerWkDay'].sum()).sort_values('AvgPurchasePerWkDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 70},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='WkDayoftheMonth',\n                   y='AvgPurchasePerWkDay',\n                   data=wkDayPurchasePerWotM_avg,\n                   order=['Mon','Tue', 'Wed', 'Thu','Fri', 'Sat', 'Sun'],\n                   ax=ax4,\n                   markers='o',\n                   linestyles='dashdot')\n\nmeanSum = wkDayPurchasePerWotM_sum['SumPurchasePerWkDay'].mean()\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(round(meanSum,1)),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='center',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = wkDayPurchasePerWotM_avg['AvgPurchasePerWkDay'].mean()\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(round(meanAvg,1)),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='center',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Day for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Day for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Week Day\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Week Day\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:35:34.458193Z","iopub.execute_input":"2022-05-27T13:35:34.458739Z","iopub.status.idle":"2022-05-27T13:37:07.409823Z","shell.execute_reply.started":"2022-05-27T13:35:34.458702Z","shell.execute_reply":"2022-05-27T13:37:07.408589Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\nwkDayPurchasePerWotM = spark.sql('''\nSELECT \n    round(avg(WkDayPurchased), 2) as AvgPurchasePerWkDay, \n    sum(WkDayPurchased) as SumPurchasePerWkDay, \n    dotw_day as WkDayoftheMonth\nFROM \n    (select sum(PurchaseYN) as WkDayPurchased, dotw_day, woty_num\n    from nov_purchased\n    group by dotw_day, woty_num)\nGROUP BY dotw_day\n''')\n\nwkDayPurchasePerWotM_sum = wkDayPurchasePerWotM.select('WkDayoftheMonth', 'SumPurchasePerWkDay').toPandas()\nwkDayPurchasePerWotM_avg = wkDayPurchasePerWotM.select('WkDayoftheMonth', 'AvgPurchasePerWkDay').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='WkDayoftheMonth',\n                   y='SumPurchasePerWkDay',\n                   data=wkDayPurchasePerWotM_sum,\n                   order=['Mon','Tue', 'Wed', 'Thu','Fri', 'Sat', 'Sun'],\n                   ax=ax1,\n                   markers='o',\n                   linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    wkDayPurchasePerWotM_sum.groupby('WkDayoftheMonth')\n    ['SumPurchasePerWkDay'].sum()).sort_values('SumPurchasePerWkDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 70},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    wkDayPurchasePerWotM_avg.groupby('WkDayoftheMonth')\n    ['AvgPurchasePerWkDay'].sum()).sort_values('AvgPurchasePerWkDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 70},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='WkDayoftheMonth',\n                   y='AvgPurchasePerWkDay',\n                   data=wkDayPurchasePerWotM_avg,\n                   order=['Mon','Tue', 'Wed', 'Thu','Fri', 'Sat', 'Sun'],\n                   ax=ax4,\n                   markers='o',\n                   linestyles='dashdot')\n\nmeanSum = wkDayPurchasePerWotM_sum['SumPurchasePerWkDay'].mean()\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(round(meanSum,1)),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='center',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = wkDayPurchasePerWotM_avg['AvgPurchasePerWkDay'].mean()\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(round(meanAvg,1)),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='center',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Day for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Day for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Week Day\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Week Day\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:39:11.203100Z","iopub.execute_input":"2022-05-27T13:39:11.203636Z","iopub.status.idle":"2022-05-27T13:41:35.814204Z","shell.execute_reply.started":"2022-05-27T13:39:11.203598Z","shell.execute_reply":"2022-05-27T13:41:35.812612Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"wkDayPurchasePerWotM = spark.sql('''\nSELECT \n    round(avg(WkDayPurchased), 2) as AvgPurchasePerWkDay, \n    sum(WkDayPurchased) as SumPurchasePerWkDay, \n    dotw_day as WkDayoftheMonth\nFROM \n    (select sum(PurchaseYN) as WkDayPurchased, dotw_day, woty_num\n    from dec_purchased\n    group by dotw_day, woty_num)\nGROUP BY dotw_day\n''')\n\nwkDayPurchasePerWotM_sum = wkDayPurchasePerWotM.select('WkDayoftheMonth', 'SumPurchasePerWkDay').toPandas()\nwkDayPurchasePerWotM_avg = wkDayPurchasePerWotM.select('WkDayoftheMonth', 'AvgPurchasePerWkDay').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='WkDayoftheMonth',\n                   y='SumPurchasePerWkDay',\n                   data=wkDayPurchasePerWotM_sum,\n                   order=['Mon','Tue', 'Wed', 'Thu','Fri', 'Sat', 'Sun'],\n                   ax=ax1,\n                   markers='o',\n                   linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    wkDayPurchasePerWotM_sum.groupby('WkDayoftheMonth')\n    ['SumPurchasePerWkDay'].sum()).sort_values('SumPurchasePerWkDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 70},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    wkDayPurchasePerWotM_avg.groupby('WkDayoftheMonth')\n    ['AvgPurchasePerWkDay'].sum()).sort_values('AvgPurchasePerWkDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 70},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='WkDayoftheMonth',\n                   y='AvgPurchasePerWkDay',\n                   data=wkDayPurchasePerWotM_avg,\n                   order=['Mon','Tue', 'Wed', 'Thu','Fri', 'Sat', 'Sun'],\n                   ax=ax4,\n                   markers='o',\n                   linestyles='dashdot')\n\nmeanSum = wkDayPurchasePerWotM_sum['SumPurchasePerWkDay'].mean()\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(round(meanSum,1)),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='center',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = wkDayPurchasePerWotM_avg['AvgPurchasePerWkDay'].mean()\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(round(meanAvg,1)),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='center',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Day for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Day for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Week Day\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Week Day\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:42:30.235951Z","iopub.execute_input":"2022-05-27T13:42:30.236385Z","iopub.status.idle":"2022-05-27T13:42:38.902286Z","shell.execute_reply.started":"2022-05-27T13:42:30.236351Z","shell.execute_reply":"2022-05-27T13:42:38.900660Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"wkDayPurchasePerWotM = spark.sql('''\nSELECT \n    round(avg(WkDayPurchased), 2) as AvgPurchasePerWkDay, \n    sum(WkDayPurchased) as SumPurchasePerWkDay, \n    dotw_day as WkDayoftheMonth\nFROM \n    (select sum(PurchaseYN) as WkDayPurchased, dotw_day, woty_num\n    from jan_purchased\n    group by dotw_day, woty_num)\nGROUP BY dotw_day\n''')\n\nwkDayPurchasePerWotM_sum = wkDayPurchasePerWotM.select('WkDayoftheMonth', 'SumPurchasePerWkDay').toPandas()\nwkDayPurchasePerWotM_avg = wkDayPurchasePerWotM.select('WkDayoftheMonth', 'AvgPurchasePerWkDay').toPandas()\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=False, sharey=False, gridspec_kw={'height_ratios': [4, 1, 1, 4]}, figsize=(12, 16))\ng1 = sns.pointplot(x='WkDayoftheMonth',\n                   y='SumPurchasePerWkDay',\n                   data=wkDayPurchasePerWotM_sum,\n                   order=['Mon','Tue', 'Wed', 'Thu','Fri', 'Sat', 'Sun'],\n                   ax=ax1,\n                   markers='o',\n                   linestyles='dashdot')\n\ng2 = sns.heatmap(pd.DataFrame(\n    wkDayPurchasePerWotM_sum.groupby('WkDayoftheMonth')\n    ['SumPurchasePerWkDay'].sum()).sort_values('SumPurchasePerWkDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 70},\n                 alpha=0.8,\n                 ax=ax2)\n\ng3 = sns.heatmap(pd.DataFrame(\n    wkDayPurchasePerWotM_avg.groupby('WkDayoftheMonth')\n    ['AvgPurchasePerWkDay'].sum()).sort_values('AvgPurchasePerWkDay',\n                                              ascending=False).T,\n                 linewidths=.2,\n                 cmap=colormap,\n                 cbar=False,\n                 fmt='.1f',\n                 annot=True,\n                 yticklabels=False,\n                 annot_kws={'rotation': 70},\n                 alpha=0.8,\n                 ax=ax3)\n\ng4 = sns.pointplot(x='WkDayoftheMonth',\n                   y='AvgPurchasePerWkDay',\n                   data=wkDayPurchasePerWotM_avg,\n                   order=['Mon','Tue', 'Wed', 'Thu','Fri', 'Sat', 'Sun'],\n                   ax=ax4,\n                   markers='o',\n                   linestyles='dashdot')\n\nmeanSum = wkDayPurchasePerWotM_sum['SumPurchasePerWkDay'].mean()\ng1.axhline(meanSum, linestyle=':', color='darkslateblue', alpha=0.5)\ng1.text(0,\n        meanSum,\n        'Average {}'.format(round(meanSum,1)),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='center',\n        color='darkslateblue',\n        alpha=0.5)\n\nmeanAvg = wkDayPurchasePerWotM_avg['AvgPurchasePerWkDay'].mean()\ng4.axhline(meanAvg,\n           linestyle=':',\n           color='lightslategrey',\n           label='Avg',\n           alpha=0.5)\ng4.text(0,\n        meanAvg,\n        'Average {}'.format(round(meanAvg,1)),\n        fontsize=10,\n        weight='bold',\n        va='bottom',\n        ha='center',\n        color='darkslateblue',\n        alpha=0.5)\n\ng1.set_title('Purchases Per Day for the Month - Timeline - Sum', fontsize=14, weight='bold')\ng4.set_title('Purchases Per Day for the Month - Timeline - Avg', fontsize=14, weight='bold')\n\n# axes titles\nax1.set(ylabel=\"Purchases\",                 xlabel=\"Week Day\")\nax2.set(ylabel='Purchases \\nOrdered \\nSum', xlabel=\" \" )\nax3.set(ylabel='Purchases \\nOrdered \\nAvg', xlabel=\" \" )\nax4.set(ylabel=\"Purchases\",                 xlabel=\"Week Day\")\n\nax1.set_yticklabels(ax1.get_yticklabels(), rotation=0)\nax3.set_yticklabels(ax1.get_yticklabels(), rotation=0)\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:42:57.553069Z","iopub.execute_input":"2022-05-27T13:42:57.553496Z","iopub.status.idle":"2022-05-27T13:43:07.375441Z","shell.execute_reply.started":"2022-05-27T13:42:57.553461Z","shell.execute_reply":"2022-05-27T13:43:07.374037Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"pdCrosstabHouravg2 = df_oct.filter('PurchaseYN == 1')\\\n    .select('event_hour','dotw_num', 'dotw_day', 'dotm_num', 'woty_num','PurchaseYN')\\\n    .toPandas().set_index(['event_hour', 'dotw_day']).sort_index()\npdCrosstabHouravg2 = pdCrosstabHouravg2.groupby(['dotw_day','event_hour', 'woty_num'])['PurchaseYN'].count()\npdCrosstabHouravg2 = pdCrosstabHouravg2.reset_index()\npdCrosstabHouravg2.rename(columns={'dotw_day': 'Week Day'}, inplace=True)\n\ng1 = sns.catplot(\n    x='event_hour',\n    y='PurchaseYN',\n    row='Week Day',\n    row_order=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n    hue='woty_num',\n    palette=palette1,\n    data=pdCrosstabHouravg2,\n    kind=\"point\",\n    markers='o',\n    linestyles='--',\n    height=6,\n    aspect=2,\n    alpha=0.4,\n    legend_out=True,\n    sharex=False,\n    margin_titles=True\n    )\ng1.set(xlabel='Hour of the Day \\n', ylabel='\\nTotal Purchase Count')\ng1._legend.set_title('Week of \\nthe Year')\ng1._legend.set_bbox_to_anchor((0.925, 0.965))\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:48:55.677585Z","iopub.execute_input":"2022-05-27T13:48:55.678034Z","iopub.status.idle":"2022-05-27T13:49:50.702506Z","shell.execute_reply.started":"2022-05-27T13:48:55.678005Z","shell.execute_reply":"2022-05-27T13:49:50.701598Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"pdCrosstabHouravg2 = df_oct.filter('PurchaseYN == 1')\\\n    .select('event_hour', 'dotw_num', 'dotw_day', 'dotm_num', 'PurchaseYN')\\\n    .toPandas().set_index(['event_hour', 'dotw_day']).sort_index()\npdCrosstabHouravg2 = pdCrosstabHouravg2.groupby(['dotw_day','event_hour'])['PurchaseYN'].count()\npdCrosstabHouravg2 = pdCrosstabHouravg2.reset_index()\n\ng1 = sns.catplot(x='event_hour',\n                 y='PurchaseYN',\n                 hue='dotw_day',\n                 palette=palette1,\n                 data=pdCrosstabHouravg2,\n                 kind='point',\n                 markers='o',\n                 linestyles='--',\n                 height=8,\n                 aspect=2,\n                 hue_order=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n                 ci=0.95,\n                 alpha=0.4)\ng1.fig.subplots_adjust(top=0.9)\ng1.fig.suptitle('Purchase Count Total by Hour by Week', fontsize=16)\ng1._legend.set_title('Week Day')\ng1.set(xlabel='Hour of the Day \\n', ylabel='Total Purchase Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:52:44.742274Z","iopub.execute_input":"2022-05-27T13:52:44.742790Z","iopub.status.idle":"2022-05-27T13:53:40.013522Z","shell.execute_reply.started":"2022-05-27T13:52:44.742756Z","shell.execute_reply":"2022-05-27T13:53:40.012602Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"pdCrosstabHouravg2 = df_nov.filter('PurchaseYN == 1')\\\n    .select('event_hour','dotw_num', 'dotw_day', 'dotm_num', 'woty_num','PurchaseYN')\\\n    .toPandas().set_index(['event_hour', 'dotw_day']).sort_index()\n\npdCrosstabHouravg2 = pdCrosstabHouravg2.groupby(['dotw_day','event_hour', 'woty_num'])['PurchaseYN'].count()\npdCrosstabHouravg2 = pdCrosstabHouravg2.reset_index()\npdCrosstabHouravg2.rename(columns={'dotw_day': 'Week Day'}, inplace=True)\n\ng1 = sns.catplot(x='event_hour',\n                 y='PurchaseYN',\n                 row='Week Day',\n                 row_order=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'],\n                 hue='woty_num',\n                 palette=palette1,\n                 data=pdCrosstabHouravg2,\n                 kind=\"point\",\n                 markers='o',\n                 linestyles='--',\n                 height=6,\n                 aspect=2,\n                 alpha=0.4,\n                 legend_out=True,\n                 sharex=False,\n                 margin_titles=True)\ng1.set(xlabel=\"Hour of the Day \\n\", ylabel='\\nTotal Purchase Count')\ng1._legend.set_title('Week of \\nthe Year')\ng1._legend.set_bbox_to_anchor((0.925,.965))\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:57:36.134286Z","iopub.execute_input":"2022-05-27T13:57:36.134857Z","iopub.status.idle":"2022-05-27T13:59:08.434125Z","shell.execute_reply.started":"2022-05-27T13:57:36.134816Z","shell.execute_reply":"2022-05-27T13:59:08.433410Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"pdCrosstabHouravg2 = df_nov.filter('PurchaseYN == 1')\\\n    .select('event_hour','dotw_num', 'dotw_day', 'dotm_num', 'PurchaseYN')\\\n    .toPandas().set_index(['event_hour', 'dotw_day']).sort_index()\n\npdCrosstabHouravg2 = pdCrosstabHouravg2.groupby(['event_hour', 'dotw_day'])['PurchaseYN'].count()\npdCrosstabHouravg2 = pdCrosstabHouravg2.reset_index()\n\ng1 = sns.catplot(\n    x='event_hour',\n    y='PurchaseYN',\n    hue='dotw_day',\n    palette=palette1,\n    data=pdCrosstabHouravg2,\n    kind=\"point\",\n    markers='o',\n    linestyles='--',\n    height=8,\n    aspect=2,\n    hue_order=['Mon', 'Tues', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun'],\n    ci=0.95,\n    alpha=0.4)\n\ng1.fig.subplots_adjust(top=0.9)\ng1.fig.suptitle('Purchase Count Total by Hour by Week', fontsize=16)\n\ng1._legend.set_title('Week Day')\ng1.set(xlabel=\"Hour of the Day \\n\", ylabel='Total Purchase Count')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-27T13:59:33.302310Z","iopub.execute_input":"2022-05-27T13:59:33.302752Z","iopub.status.idle":"2022-05-27T14:00:54.701651Z","shell.execute_reply.started":"2022-05-27T13:59:33.302718Z","shell.execute_reply":"2022-05-27T14:00:54.700702Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"Machine Learning","metadata":{}}]}