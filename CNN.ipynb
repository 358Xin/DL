{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2Q3KG+lfS5fCt11YcGLRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/358Xin/DL/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFWtzP3KADuo",
        "outputId": "47f3a083-5fbb-4ac4-be86-33696594be09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1awF7pZ9Dz7X1jn1_QAiKN-_v56veCEKy\n",
            "To: /content/food-11.zip\n",
            "100% 963M/963M [00:05<00:00, 170MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id '1awF7pZ9Dz7X1jn1_QAiKN-_v56veCEKy' --output food-11.zip\n",
        "!unzip -q food-11.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import ConcatDataset, Dataset, Subset\n",
        "from torchvision.datasets import DatasetFolder\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "UrY-uw65B5U5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])\n",
        "test_transform = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "KIyJuczoCcqd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.functional import broadcast_shapes\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 128\n",
        "\n",
        "train_set = DatasetFolder(\"food-11/training/labeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_transform)\n",
        "valid_set = DatasetFolder(\"food-11/validation\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_transform)\n",
        "unlabeled_set = DatasetFolder(\"food-11/training/unlabeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_transform)\n",
        "test_set = DatasetFolder(\"food-11/testing\", loader=lambda x: Image.opne(x), extensions=\"jpg\", transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5a6_VEuC9Vh",
        "outputId": "a83ab007-9296-45d5-994c-e22dafa3bc0b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.pooling import MaxPool2d\n",
        "from torch.nn.modules.conv import Conv2d\n",
        "from torch.nn.modules.batchnorm import BatchNorm2d\n",
        "class Classifier:\n",
        "  def __init__(self):\n",
        "    super(Classifier, self).__init__()\n",
        "\n",
        "    self.cnn_layers = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, 3, 1, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2,0),\n",
        "\n",
        "        nn.Conv2d(64, 128, 3, 1, 1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2, 0),\n",
        "\n",
        "        nn.Conv2d(128, 256, 3, 1, 1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(4, 4, 0)\n",
        "    )\n",
        "\n",
        "    self.fc_layers = nn.Sequential(\n",
        "        nn.Linear(256*8*8, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 11)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.cnn_layers(x)\n",
        "    x = x.flatten(1)\n",
        "    x = self.fc_layers(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "dQw7eG3QEpul"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pseudo_labels(dataset, model, threshold=0.65):\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  \n",
        "  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  model.eval()\n",
        "  softmax = nn.Softmax(-1)\n",
        "  for batch in tqdm(data_loader):\n",
        "    img, _ = batch\n",
        "    with torch.no_grad():\n",
        "      logits = model(img.to(device))\n",
        "    probs = softmax(logits)\n",
        "  model.train()\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "wcsDezI_GaZR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = Classifier().to(device)\n",
        "model.device = device\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n",
        "n_epochs = 80\n",
        "do_semi = False\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  if do_semi:\n",
        "    pseudo_set = get_pseudo_labels(unlabeled_set, model)\n",
        "    concat_dataset = ConcatDataset([train_set, pseudo_set])\n",
        "    train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "  model.train()\n",
        "  train_loss = []\n",
        "  train_acc = []\n",
        "\n",
        "  for batch in tqdm(train_loader):\n",
        "    img, label = batch\n",
        "    logits = model(img.to(device))\n",
        "    loss = criterion(logits, label.to(device))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    "
      ],
      "metadata": {
        "id": "lMs7vepvHXCz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}